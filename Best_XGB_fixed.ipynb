{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f157f7f4-f1fc-41a2-baf1-31c57cee9afd",
   "metadata": {},
   "source": [
    "## Heart Attack Risk with XGBoost classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7613181-95cd-469f-be34-b670233bceb2",
   "metadata": {},
   "source": [
    "#### **1) Pip install packages & library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db52fee9-2227-4550-8c31-3e0fb426783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.13/site-packages (0.13.0)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.13/site-packages (3.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.13/site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (1.16.5)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.13/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.13/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.13/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Status游릭: Pip Install complete\n"
     ]
    }
   ],
   "source": [
    "# Install packages needed for running code\n",
    "%pip install pandas numpy scikit-learn imbalanced-learn xgboost matplotlib optuna openai joblib\n",
    "print(\"Status游릭: Pip Install complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283bb4c3-a551-491d-9ae6-2e19c250d628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Importing libraries complete\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import joblib\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"Status游릭: Importing libraries complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b2f80-2cb0-4e1d-a6b8-9ccc746b94e3",
   "metadata": {},
   "source": [
    "#### **2) Load dataframe from Google Drive & seperate in Features and Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e44c3da-5773-456a-b392-065894fd2fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively load csv from local path (Offline Option - insert path to 2022_no_nans csv)\n",
    "# path = \"heart_2022_no_nans.csv\"\n",
    "# df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55f3a3be-58b8-4f75-a10b-074aee7da155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Csv loading complete; Heart Attack column mapped & saved in y; Target & State removed from X\n"
     ]
    }
   ],
   "source": [
    "# Load csv from google drive (Universal Option)\n",
    "file_id = \"1MMG-VyOMRrMRMcelEAnm9GCseOcgRsgD\"\n",
    "url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "df = pd.read_csv(url)\n",
    "# Load features used for prediction into DataFrame X\n",
    "feature_columns = [\n",
    "    \"AgeCategory\",\n",
    "    \"ChestScan\",\n",
    "    \"HadAngina\",\n",
    "    \"GeneralHealth\",\n",
    "    \"PhysicalHealthDays\",\n",
    "    \"SmokerStatus\",\n",
    "    \"ECigaretteUsage\",\n",
    "    \"HadDiabetes\",\n",
    "    \"BMI\",\n",
    "    \"PhysicalActivities\",\n",
    "    \"DifficultyWalking\",\n",
    "    \"HadCOPD\",\n",
    "    \"HadStroke\",\n",
    "    \"SleepHours\",\n",
    "    \"HadDepressiveDisorder\",\n",
    "    \"AlcoholDrinkers\",\n",
    "    \"LastCheckupTime\"\n",
    "]\n",
    "X = df[feature_columns]\n",
    "y = df[\"HadHeartAttack\"].map({\"Yes\": 1, \"No\": 0})                     # Save prediction target as y\n",
    "\n",
    "print(\"Status游릭: Csv loading complete; Heart Attack column mapped & saved in y; Target & State removed from X\" if not df.empty else \"Status游: CSV load failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4198c6f8-f374-401f-8b02-1becb4e392b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df columns: 40 - should be 40\n",
      "X feature columns: 17 - should be 17\n",
      "y target columns: 1 - should be 1\n"
     ]
    }
   ],
   "source": [
    "# Check if Target / Feature separation worked\n",
    "print(f\"Original df columns: {df.shape[1]} - should be 40\")                                  # Column count Dataframe\n",
    "print(f\"X feature columns: {X.shape[1]} - should be 17\")                                     # Column Count Features\n",
    "print(f\"y target columns: {y.shape[1] if y.ndim > 1 else 1} - should be 1\")                  # Column Count Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb881ae-ac75-42eb-a146-e4f475332120",
   "metadata": {},
   "source": [
    "#### **3) Train, Test, Split & Preprocessing pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06ef4e87-c243-4406-9619-e6b7711468bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Preprocessor for pipeline works; Train_test_split complete\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split training/ testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Differenciate categorical and numerical columns (different preprocessing approach)  \n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Preprocessor - Scaling for numerical columns, Encoding categorical columns\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"num\", StandardScaler(), num_cols)])  \n",
    "\n",
    "# Check if preprocessor turns all data into numericals (for later model use)\n",
    "print(\"Status游릭: Preprocessor for pipeline works; Train_test_split complete\" \n",
    "      if np.issubdtype(preprocessor.fit_transform(X_train).dtype, np.number) \n",
    "      else \"Status游: Preprocesser issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af54f64-78b2-4603-b5b4-9fabefd3b17d",
   "metadata": {},
   "source": [
    "#### **4) Optimizing XBG learning parameters with Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8061f27-0bcf-4601-9ab8-223fc1d73435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 15:41:05,454] A new study created in memory with name: no-name-dd95f9e5-b5d3-403c-8420-29ff14c5f40b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Optuna Optimizer Heart Disease starts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874f257829ec4a4f9aea1846142d4558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-11 15:41:08,637] Trial 0 failed with parameters: {'n_estimators': 443, 'max_depth': 6, 'learning_rate': 0.08031420409722674, 'subsample': 0.8027526013781195, 'colsample_bytree': 0.8623056682082835, 'min_child_weight': 2.4662513592754904, 'gamma': 0.24478449072763364} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/37/4gbwkhqj12v7ywvlm_hd44g40000gn/T/ipykernel_10619/2493635494.py\", line 29, in objective\n",
      "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=1)     # Evaluate ROC-AUC, because test has imbalanced data\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 684, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 411, in cross_validate\n",
      "    results = parallel(\n",
      "        delayed(_fit_and_score)(\n",
      "    ...<15 lines>...\n",
      "        for train, test in indices\n",
      "    )\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ~~~~^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/imblearn/pipeline.py\", line 526, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "                    ~~~~~^\n",
      "        params,\n",
      "        ^^^^^^^\n",
      "    ...<9 lines>...\n",
      "        callbacks=self.callbacks,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py\", line 2434, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self.handle, ctypes.c_int(iteration), dtrain.handle\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-11 15:41:08,647] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus游릭: Optuna Optimizer Heart Disease starts\u001b[39m\u001b[38;5;124m\"\u001b[39m)     \n\u001b[1;32m     33\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)                                 \u001b[38;5;66;03m# search for the maximal AUC\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)                    \u001b[38;5;66;03m# Run 20 different hyperparameter trials and show progress\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus游릭:Parameters optimized, best result at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     _optimize(\n\u001b[1;32m    491\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    492\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    493\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    494\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    495\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    496\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    497\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    498\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    499\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    500\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         _optimize_sequential(\n\u001b[1;32m     68\u001b[0m             study,\n\u001b[1;32m     69\u001b[0m             func,\n\u001b[1;32m     70\u001b[0m             n_trials,\n\u001b[1;32m     71\u001b[0m             timeout,\n\u001b[1;32m     72\u001b[0m             catch,\n\u001b[1;32m     73\u001b[0m             callbacks,\n\u001b[1;32m     74\u001b[0m             gc_after_trial,\n\u001b[1;32m     75\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[90], line 29\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 5-fold CV so every fold has the same target 0/1 ratio - prevent folds where the minority class is missing (would break training and evaluation).\u001b[39;00m\n\u001b[1;32m     28\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)           \n\u001b[0;32m---> 29\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(pipe, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)     \u001b[38;5;66;03m# Evaluate ROC-AUC, because test has imbalanced data\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    685\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    686\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    687\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    688\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    689\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    690\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    691\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    692\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    693\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    694\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    695\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    412\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m         clone(estimator),\n\u001b[1;32m    414\u001b[0m         X,\n\u001b[1;32m    415\u001b[0m         y,\n\u001b[1;32m    416\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    417\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    418\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    419\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    420\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    421\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    422\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    423\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    424\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    425\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    426\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/imblearn/pipeline.py:526\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    521\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    522\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    523\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    524\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    525\u001b[0m         )\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, yt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/sklearn.py:1806\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1786\u001b[0m evals_result: EvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1787\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1788\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1789\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m   1804\u001b[0m )\n\u001b[0;32m-> 1806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1807\u001b[0m     params,\n\u001b[1;32m   1808\u001b[0m     train_dmatrix,\n\u001b[1;32m   1809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1810\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[1;32m   1811\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1812\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[1;32m   1813\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[1;32m   1814\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m   1815\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1816\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m   1817\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[1;32m   1818\u001b[0m )\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/training.py:199\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:2434\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2433\u001b[0m     _check_call(\n\u001b[0;32m-> 2434\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[1;32m   2435\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   2436\u001b[0m         )\n\u001b[1;32m   2437\u001b[0m     )\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGB performance depends on learning parameters; Optuna tests small trial models to find the most effective with dataset\n",
    "# Entire Optuna run ~2h - move foreward to next cell to use fixed optimal parameters (calculated by previous run)\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"                                 # prevent warning on not found core count\n",
    "def objective(trial):                                                  # at each trial\n",
    "    # pos_weight = sum(y_train == 0) / sum(y_train == 1)               # pos_weight to counter imbalanced target count 0/1 in dataset not used anymore, as \n",
    "                                                                       # SMOTE is used later creates synthetic minority samples for class balance\n",
    "    params = {                                                         # Parameter search space Optuna explores during tuning (regular for tabular data)\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 1000),  \n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 6),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 3),\n",
    "        # \"scale_pos_weight\": pos_weight,\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": 1,\n",
    "        \"eval_metric\": \"auc\"}\n",
    "\n",
    "    model = XGBClassifier(**params)                     # Temporary trial-model for testing parameter samples\n",
    "    pipe = ImbPipeline(steps=[                          # pipeline to include preprocessing, SMOTE, model (XGB with optimal params)\n",
    "        (\"preprocessor\", preprocessor),   \n",
    "        (\"smote\", SMOTE(random_state=42)),              # Apply smote to fix class imbalance\n",
    "        (\"model\", model)])\n",
    "\n",
    "    # 5-fold CV so every fold has the same target 0/1 ratio - prevent folds where the minority class is missing (would break training and evaluation).\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)           \n",
    "    scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=1)     # Evaluate ROC-AUC, because test has imbalanced data\n",
    "    return np.mean(scores)                                                                   # Return the trial뗩 average score to compare\n",
    "\n",
    "print(\"Status游릭: Optuna Optimizer Heart Disease starts\")     \n",
    "study = optuna.create_study(direction=\"maximize\")                                 # search for the maximal AUC\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)                    # Run 20 different hyperparameter trials and show progress\n",
    "print(\"Status游릭:Parameters optimized, best result at:\", study.best_params)       # Show best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "352e7860-b58f-49a5-b690-f1c1c7eb2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Loading fixed best params complete\n"
     ]
    }
   ],
   "source": [
    "# Parameters for XGBoost (Actual Optuna run takes 2hours)\n",
    "params_str = \"{'n_estimators': 815,'max_depth': 3,'learning_rate': 0.07614460224904332,'subsample': 0.8000780438143853,'colsample_bytree': 0.92339638672124,'min_child_weight': 5.153117405217333,'gamma': 2.5284744287225296}\"\n",
    "best_params = eval(params_str)\n",
    "# best_params = study.best_params               # If full optuna run complete, uncomment\n",
    "print(\"Status游릭: Loading fixed best params complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054d090-5a6d-4763-b69c-cfddbd791766",
   "metadata": {},
   "source": [
    "#### **5) Final Model Pipeline, XBGoost Training & Model save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a554a60-a4af-4454-bbfc-16cfc98c1ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Final Pipeline using best params built, steps including \n",
      "  1) Preprocess steps:\n",
      "  - cat: OneHotEncoder on 14 columns\n",
      "  - num: StandardScaler on 3 columns\n",
      "  2) Final Pipeline steps\n",
      "  - preprocessor: ColumnTransformer\n",
      "  - smote: SMOTE\n",
      "  - model: XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "# Finale Pipeline for actual Model (dont forget to load best params from above cell!)\n",
    "\n",
    "final_model = XGBClassifier(            # final XGBoost model (with parameters) to be trained on the data\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    eval_metric=\"auc\")\n",
    "\n",
    "pipe_final = ImbPipeline(steps=[        # Create the final pipeline with preprocessing, SMOTE, and the final model\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"model\", final_model)])\n",
    "\n",
    "print(f\"Status游릭: Final Pipeline using best params built, steps including \\n  1) Preprocess steps:\")\n",
    "for name, transformer, cols in preprocessor.transformers:                                  # Show all preprocess steps (Encode, Scale) included\n",
    "    print(f\"  - {name}: {transformer.__class__.__name__} on {len(cols)} columns\")\n",
    "print(\"  2) Final Pipeline steps\")\n",
    "for name, step in pipe_final.steps:                                                        # Show all final pipeline steps included\n",
    "    print(f\"  - {name}: {step.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be2997d3-7cbd-46a8-b1a9-18ae5afd43bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status 游릭: Training final model...\n",
      "Status 游릭: Evaluating final model...\n",
      "Status 游릭: Final Test AUC: 0.8654\n"
     ]
    }
   ],
   "source": [
    "# Train final model \n",
    "print(\"Status 游릭: Training final model...\")\n",
    "pipe_final.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on untouched test set\n",
    "print(\"Status 游릭: Evaluating final model...\")\n",
    "y_pred = pipe_final.predict(X_test)\n",
    "y_proba = pipe_final.predict_proba(X_test)[:, 1]\n",
    "roc_auc_max = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"Status 游릭: Final Test AUC: {roc_auc_max:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "272f6900-1ce6-413c-b218-5a10c10585e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status 游릭: Model save complete\n"
     ]
    }
   ],
   "source": [
    "# save model for later \n",
    "joblib.dump(pipe_final, \"final_heart_model.pkl\")\n",
    "print(\"Status 游릭: Model save complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eae591be-19d5-48c4-93cb-a91f61354654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status 游릭: Model load complete\n"
     ]
    }
   ],
   "source": [
    "# load model for later \n",
    "pipe_final = joblib.load(\"final_heart_model.pkl\")\n",
    "print(\"Status 游릭: Model load complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f641d-eca2-4531-a3f8-32f443529e66",
   "metadata": {},
   "source": [
    "## From here, model training is complete. The Web App provides the following features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91212d7e-3246-4b55-8b53-8dd51eb63d49",
   "metadata": {},
   "source": [
    "#### **1) Choose random person or insert own values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ed44f6f-7251-494e-961f-237fd430d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status游릭: Random person chosen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>PhysicalHealthDays</th>\n",
       "      <th>MentalHealthDays</th>\n",
       "      <th>LastCheckupTime</th>\n",
       "      <th>PhysicalActivities</th>\n",
       "      <th>SleepHours</th>\n",
       "      <th>RemovedTeeth</th>\n",
       "      <th>HadHeartAttack</th>\n",
       "      <th>...</th>\n",
       "      <th>HeightInMeters</th>\n",
       "      <th>WeightInKilograms</th>\n",
       "      <th>BMI</th>\n",
       "      <th>AlcoholDrinkers</th>\n",
       "      <th>HIVTesting</th>\n",
       "      <th>FluVaxLast12</th>\n",
       "      <th>PneumoVaxEver</th>\n",
       "      <th>TetanusLast10Tdap</th>\n",
       "      <th>HighRiskLastYear</th>\n",
       "      <th>CovidPos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215466</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Male</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Within past year (anytime less than 12 months ...</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None of them</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>77.11</td>\n",
       "      <td>29.18</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No, did not receive any tetanus shot in the pa...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows 칑 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             State   Sex GeneralHealth  PhysicalHealthDays  MentalHealthDays  \\\n",
       "215466  Washington  Male     Excellent                 0.0               0.0   \n",
       "\n",
       "                                          LastCheckupTime PhysicalActivities  \\\n",
       "215466  Within past year (anytime less than 12 months ...                 No   \n",
       "\n",
       "        SleepHours  RemovedTeeth HadHeartAttack  ... HeightInMeters  \\\n",
       "215466         7.0  None of them             No  ...           1.63   \n",
       "\n",
       "       WeightInKilograms    BMI AlcoholDrinkers HIVTesting FluVaxLast12  \\\n",
       "215466             77.11  29.18              No         No           No   \n",
       "\n",
       "       PneumoVaxEver                                  TetanusLast10Tdap  \\\n",
       "215466            No  No, did not receive any tetanus shot in the pa...   \n",
       "\n",
       "       HighRiskLastYear CovidPos  \n",
       "215466               No       No  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose random person from data set (skip time to fill in yourself)\n",
    "random_person = df.sample(1) \n",
    "print(\"Status游릭: Random person chosen\") if len(random_person) != 0 else print (\"Status游: Random person not working\")\n",
    "random_person.head()      # Check random person datafrane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "114c7bbb-2968-49b7-b062-957f6dd71868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible Values/ Value type for each column - to know what can be inserted as personal data\n",
    "#for col in X.columns:                                # only needed during coding, not now\n",
    "#    print(col)\n",
    "#    print(df[col].unique())\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "361272c5-448d-4144-8b6e-abe47314cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Own Values insertion (overwrites random person) - fill in or rerun random person chooser\n",
    "# When filling in use options in the comments behind, or select in streamlit interface\n",
    "random_person = pd.DataFrame([{\n",
    "    \"AgeCategory\":\"\", #int\n",
    "    \"ChestScan\":\"\", #Yes/ No\n",
    "    \"HadAngina\":\"\", #Yes/ No\n",
    "    \"GeneralHealth\":\"\", #Excellent, Very good, Good, Fair, Poor\n",
    "    \"PhysicalHealthDays\":\"\", #int\n",
    "    \"SmokerStatus\":\"\", #Former smoker, Never smoked, Current smoker - now smokes every day, Current smoker - now smokes some days\n",
    "    \"ECigaretteUsage\":\"\", # 'Never used e-cigarettes in my entire life', 'Use them some days', 'Not at all (right now)', 'Use them every day'\n",
    "    \"HadDiabetes\":\"\", #Yes/ No\n",
    "    \"BMI\":\"\", #int\n",
    "    \"PhysicalActivities\":\"\", #Yes/ No\n",
    "    \"DifficultyWalking\":\"\", #Yes/ No\n",
    "    \"HadCOPD\":\"\", #Yes/ No\n",
    "    \"HadStroke\":\"\", #Yes/ No\n",
    "    \"SleepHours\":\"\", #int\n",
    "    \"HadDepressiveDisorder\":\"\", #Yes/ No\n",
    "    \"AlcoholDrinkers\":\"\", #Yes/ No\n",
    "    \"LastCheckupTime\": \"\" # Within past year (anytime less than 12 months ago), 5 or more years ago,\n",
    "                          # Within past 2 years (1 year but less than 2 years ago), Within past 5 years (2 years but less than 5 years ago)\n",
    "    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4ba16-6b47-484d-bfb1-db4c7596c1a7",
   "metadata": {},
   "source": [
    "##### 游릭 **Person with good Health & Low risk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a97fa24f-7f54-4d09-ab6c-3cf64b0697d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person example with good Health/habits & Low Risk\n",
    "random_person = pd.DataFrame([{\n",
    "    \"State\": \"to be dropped\",      \"Sex\": \"Male\",    \"GeneralHealth\": \"Excellent\",    \"PhysicalHealthDays\": 0,    \"MentalHealthDays\": 0,\n",
    "    \"LastCheckupTime\": \"Within past year (anytime less than 12 months ago)\",    \"PhysicalActivities\": \"Yes\",    \"SleepHours\": 8,    \n",
    "    \"RemovedTeeth\": \"None of them\",\n",
    "\n",
    "    \"HadHeartAttack\": \"to be dropped\",     \"HadAngina\": \"No\",    \"HadStroke\": \"No\",    \"HadAsthma\": \"No\",    \"HadSkinCancer\": \"No\",\n",
    "    \"HadCOPD\": \"No\",    \"HadDepressiveDisorder\": \"No\",    \"HadKidneyDisease\": \"No\",    \"HadArthritis\": \"No\",    \"HadDiabetes\": \"No\",\n",
    "\n",
    "    \"DeafOrHardOfHearing\": \"No\",    \"BlindOrVisionDifficulty\": \"No\",    \"DifficultyConcentrating\": \"No\",    \"DifficultyWalking\": \"No\",\n",
    "    \"DifficultyDressingBathing\": \"No\",    \"DifficultyErrands\": \"No\",\n",
    "\n",
    "    \"SmokerStatus\": \"Never smoked\",    \"ECigaretteUsage\": \"Never used e-cigarettes in my entire life\",    \"ChestScan\": \"No\",\n",
    "    \"RaceEthnicityCategory\": \"White only, Non-Hispanic\",    \"AgeCategory\": \"Age 30 to 34\",    \"HeightInMeters\": 1.75,\n",
    "    \"WeightInKilograms\": 70.0,    \"BMI\": 22.9,    \"AlcoholDrinkers\": \"No\",    \"HIVTesting\": \"No\",    \"FluVaxLast12\": \"No\",\n",
    "    \"PneumoVaxEver\": \"No\",    \"TetanusLast10Tdap\": \"No, did not receive any tetanus shot in the past 10 years\",    \"HighRiskLastYear\": \"No\",\n",
    "    \"CovidPos\": \"No\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb4d43-4a4d-476a-a883-f37b8dab9ca4",
   "metadata": {},
   "source": [
    "##### **救 Person with bad Health & High risk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a1d36-3289-47f7-9263-c6e4894d0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person example with bad health/habits & High Risk\n",
    "random_person = pd.DataFrame([{\n",
    "    \"AgeCategory\": 70,\n",
    "    \"ChestScan\": \"Yes\",\n",
    "    \"HadAngina\": \"Yes\",\n",
    "    \"GeneralHealth\": \"Poor\",\n",
    "    \"PhysicalHealthDays\": 20,\n",
    "    \"SmokerStatus\": \"Current smoker - now smokes every day\",\n",
    "    \"ECigaretteUsage\": \"Use them every day\",\n",
    "    \"HadDiabetes\": \"Yes\",\n",
    "    \"BMI\": 35,\n",
    "    \"PhysicalActivities\": \"No\",\n",
    "    \"DifficultyWalking\": \"Yes\",\n",
    "    \"HadCOPD\": \"Yes\",\n",
    "    \"HadStroke\": \"Yes\",\n",
    "    \"SleepHours\": 4,\n",
    "    \"HadDepressiveDisorder\": \"Yes\",\n",
    "    \"AlcoholDrinkers\": \"Yes\",\n",
    "    \"LastCheckupTime\": \"5 or more years ago\"\n",
    "}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b0ae6-9e0d-4460-a760-557879d65825",
   "metadata": {},
   "source": [
    "#### **2) Risk Assessment using Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "51127d26-1926-4416-98f5-209b05bec6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person has High Risk 救뎊n"
     ]
    }
   ],
   "source": [
    "# Risk Assessment of random person / own values\n",
    "feature_columns = [\n",
    "    \"AgeCategory\",\n",
    "    \"ChestScan\",\n",
    "    \"HadAngina\",\n",
    "    \"GeneralHealth\",\n",
    "    \"PhysicalHealthDays\",\n",
    "    \"ECigaretteUsage\",\n",
    "    \"SmokerStatus\",\n",
    "    \"HadDiabetes\",\n",
    "    \"BMI\",\n",
    "    \"PhysicalActivities\",\n",
    "    \"DifficultyWalking\",\n",
    "    \"HadCOPD\",\n",
    "    \"HadStroke\",\n",
    "    \"SleepHours\",\n",
    "    \"HadDepressiveDisorder\",\n",
    "    \"AlcoholDrinkers\",\n",
    "    \"LastCheckupTime\"\n",
    "]\n",
    "\n",
    "random_person_df = random_person[feature_columns]                                       # only load features for prediction\n",
    "pipe_final = joblib.load(\"final_heart_model.pkl\")                                       # load model plk again\n",
    "random_person_pred = pipe_final.predict(random_person_df)                               # Predict if person is at risk for an Heart Attack or not\n",
    "\n",
    "print(\"Person has High Risk 救뎊" if random_person_pred == 1 else \"Person has Low Risk 游릭\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32104156-3de4-45e4-86b8-c86c4bd0df6e",
   "metadata": {},
   "source": [
    "#### **3) Graph for comparison to average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b77f91a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2733294543.py, line 164)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[126], line 164\u001b[0;36m\u001b[0m\n\u001b[0;31m    plt.tight_layout()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Features that should be shown in graph\n",
    "features = [\n",
    "    'AgeCategory',\n",
    "    'GeneralHealth',\n",
    "    'PhysicalHealthDays',\n",
    "    'SmokerStatus',\n",
    "    'BMI',\n",
    "    'PhysicalActivities',\n",
    "    'SleepHours',\n",
    "    'AlcoholDrinkers',\n",
    "    'LastCheckupTime'\n",
    "    ]\n",
    "\n",
    "df_feat = df[features].copy()                                                      # Copy only shown features, for random_person / df\n",
    "rp_feat = random_person[features].copy()\n",
    "\n",
    "# Translate columns into numericals to calculate mean/ compare   \n",
    "mappers = {\"GeneralHealth\": {\"Poor\":0,\"Fair\":1,\"Good\":2,\"Very good\":3,\"Excellent\":4},\n",
    "           \n",
    "           \"AgeCategory\": {\"Age 18 to 24\": 21, \"Age 25 to 29\": 27, \"Age 30 to 34\": 32, \"Age 35 to 39\": 37,\n",
    "           \"Age 40 to 44\": 42, \"Age 45 to 49\": 47, \"Age 50 to 54\": 52, \"Age 55 to 59\": 57,\"Age 60 to 64\": 62, \n",
    "           \"Age 65 to 69\": 67, \"Age 70 to 74\": 72, \"Age 75 to 79\": 77, \"Age 80 or older\": 82},\n",
    "           \n",
    "           \"LastCheckupTime\": {\"5 or more years ago\":0, \"Within past 5 years (2 years but less than 5 years ago)\":1, \n",
    "           \"Within past 2 years (1 year but less than 2 years ago)\":2, \"Within past year (anytime less than 12 months ago)\":3},\n",
    "           \n",
    "           \"PhysicalActivities\": {\"Yes\":1, \"No\":0},\n",
    "           \"SmokerStatus\": {\"Current smoker - now smokes every day\":3, \"Current smoker - now smokes some days\":2,\n",
    "           \"Former smoker\":1, \"Never smoked\":0},\n",
    "           \"ECigaretteUsage\": {\"Never used e-cigarettes in my entire life\": 0, \"Not at all (right now)\": 1, \"Use them some days\": 2,\"Use them every day\": 3},\n",
    "           \"AlcoholDrinkers\": {\"No\":0, \"Yes\":1}\n",
    "           }\n",
    "\n",
    "# Mapping for both dataframes\n",
    "for col, mapping in mappers.items():\n",
    "    df_feat[col] = df_feat[col].map(mapping)\n",
    "    rp_feat[col] = rp_feat[col].map(mapping)\n",
    "    \n",
    "# df_feat.head()\n",
    "# rp_feat.head()\n",
    "\n",
    "# Mean & Values for comparison  \n",
    "df_avg = df_feat.mean()\n",
    "rp_values = rp_feat.iloc[0]\n",
    "\n",
    "x = np.arange(len(features))                       # Fit plot to count of features\n",
    "avg_vals = df_avg.values                           # Take values from both dataframes\n",
    "rp_vals  = rp_values.values                        \n",
    "\n",
    "# For each feature if Higher is good/ bad - so markings are the right way round\n",
    "higher_better = np.array([\n",
    "    False,   # AgeCategory: higher = worse\n",
    "    True,    # GeneralHealth: higher = better\n",
    "    False,   # PhysicalHealthDays: higher = worse\n",
    "    False,   # SmokerStatus: higher = better (Never smoked > daily smoking)\n",
    "    False,   # BMI: higher = worse\n",
    "    True,    # PhysicalActivities: higher = better\n",
    "    True,    # SleepHours: higher = better\n",
    "    False,   # AlcoholDrinkers: higher = better (No > Yes)\n",
    "    True   # LastCheckupTime: higher = better\n",
    "    ])  \n",
    "better_mask = np.where(higher_better, rp_vals > avg_vals, rp_vals < avg_vals)    # If higher / lower better\n",
    "\n",
    "\n",
    "# Simple scaling for even ranges in each column\n",
    "df_min = df_feat[features].min().values\n",
    "df_max = df_feat[features].max().values\n",
    "avg_scaled = (avg_vals - df_min) / (df_max - df_min)\n",
    "rp_scaled  = (rp_vals  - df_min) / (df_max - df_min)\n",
    "\n",
    "\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "# Smooth x-axis for interpolation\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300) \n",
    "\n",
    "# Smooth curves for your values and average\n",
    "spl_you = PchipInterpolator(x, rp_scaled)\n",
    "spl_avg = PchipInterpolator(x, avg_scaled)\n",
    "rp_smooth = spl_you(x_smooth)\n",
    "avg_smooth = spl_avg(x_smooth)\n",
    "# Apply mappings\n",
    "for col, mapping in mappers.items():\n",
    "    df_feat[col] = df_feat[col].map(mapping)\n",
    "    rp_feat[col] = rp_feat[col].map(mapping)\n",
    "\n",
    "# Ensure numeric for continuous vars\n",
    "df_feat[\"SleepHours\"] = df_feat[\"SleepHours\"].astype(float)\n",
    "rp_feat[\"SleepHours\"] = rp_feat[\"SleepHours\"].astype(float)\n",
    "df_feat[\"BMI\"] = df_feat[\"BMI\"].astype(float)\n",
    "rp_feat[\"BMI\"] = rp_feat[\"BMI\"].astype(float)\n",
    "\n",
    "# Mean & person values\n",
    "df_avg = df_feat.mean()\n",
    "rp_values = rp_feat.iloc[0]\n",
    "\n",
    "x = np.arange(len(features))\n",
    "avg_vals = df_avg.values\n",
    "rp_vals = rp_values.values\n",
    "\n",
    "higher_better = np.array([\n",
    "    True,   # GeneralHealth: higher = better\n",
    "    False,  # AgeCategory: higher = worse\n",
    "    False,  # PhysicalHealthDays: higher = worse\n",
    "    True,   # LastCheckupTime: higher = better\n",
    "    True,   # PhysicalActivities: higher = better\n",
    "    True,   # SleepHours: higher = better (bis zu einem Punkt)\n",
    "    False,  # SmokerStatus: higher = schlechter\n",
    "    False,  # ECigaretteUsage: h칬her = schlechter\n",
    "    False,  # AlcoholDrinkers: No (0) besser als Yes (1)\n",
    "    False   # BMI: h칬her = schlechter\n",
    "])\n",
    "\n",
    "better_mask = np.where(higher_better, rp_vals > avg_vals, rp_vals < avg_vals)\n",
    "\n",
    "# Scaling 01\n",
    "df_min = df_feat[features].min().values\n",
    "df_max = df_feat[features].max().values\n",
    "\n",
    "avg_scaled = (avg_vals - df_min) / (df_max - df_min)\n",
    "rp_scaled = (rp_vals - df_min) / (df_max - df_min)\n",
    "\n",
    "\n",
    "            \n",
    "# Smooth x-axis\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "\n",
    "# Smooth curves\n",
    "spl_you = PchipInterpolator(x, rp_scaled)\n",
    "spl_avg = PchipInterpolator(x, avg_scaled)\n",
    "\n",
    "rp_smooth = spl_you(x_smooth)\n",
    "avg_smooth = spl_avg(x_smooth)\n",
    "\n",
    "# Plot showcase and markings if better/worse\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_smooth, rp_smooth, label=\"Your values\", color=\"#0098df\")\n",
    "plt.plot(x_smooth, avg_smooth, label=\"Average\", color=\"#fb4a4a\")\n",
    "\n",
    "# saubere Segmentgrenzen ohne L칲cke\n",
    "bounds = np.concatenate(([x[0] - 0.5],\n",
    "                         (x[:-1] + x[1:]) / 2,\n",
    "                        [x[-1] + 0.5]))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    seg = (x_smooth >= bounds[i]) & (x_smooth <= bounds[i+1])\n",
    "    color = \"#0a6917\" if better_mask[i] else \"#fb4a4a\"\n",
    "    plt.fill_between(x_smooth[seg], rp_smooth[seg], avg_smooth[seg],\n",
    "                    alpha=0.5, color=color)\n",
    "\n",
    "            \n",
    "ax = plt.gca()\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])     \n",
    "plt.xticks(x, ['General Health', 'Age', 'Physical Health Days', \n",
    "                'Last Checkup', 'Physcial Activities', 'Sleep Duration', \n",
    "                'Smoking Habits', 'E-Cigarette Use', 'Alcohol Consumption', \n",
    "                'BMI'], \n",
    "                rotation=30, ha=\"right\")\n",
    "plt.title(\"You vs. Average\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            st.pyplot(plt.gcf())\n",
    "\n",
    "# Smooth mask (must be expanded)\n",
    "better_mask_smooth = np.interp(x_smooth, x, better_mask.astype(int)).astype(bool)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_smooth, rp_smooth, label=\"Your values\", color=\"#117eb0\")\n",
    "plt.plot(x_smooth, avg_smooth, label=\"Average\", color=\"#fd5c47\")\n",
    "\n",
    "# green = better, red = worse (smooth areas)\n",
    "# Difference & sign\n",
    "hb_smooth = np.interp(x_smooth, x, higher_better.astype(int)) > 0.5  # True = higher is better\n",
    "\n",
    "better = np.where(\n",
    "    hb_smooth,\n",
    "    rp_smooth >= avg_smooth,   # h칬her ist besser\n",
    "    rp_smooth <= avg_smooth    # niedriger ist besser\n",
    ")\n",
    "\n",
    "sign = np.where(better, 1, -1)\n",
    "\n",
    "change_idx = np.where(np.diff(sign) != 0)[0]\n",
    "starts = np.r_[0, change_idx + 1]\n",
    "ends   = np.r_[change_idx, len(x_smooth) - 1]\n",
    "\n",
    "# Segmente + Inseln entfernen: wenn Nachbarfarben gleich, nimm deren Farbe\n",
    "segments = []\n",
    "for s, e in zip(starts, ends):\n",
    "    segments.append([s, e, bool(better[s])])\n",
    "\n",
    "for i in range(1, len(segments) - 1):\n",
    "    if segments[i-1][2] == segments[i+1][2] != segments[i][2]:\n",
    "        segments[i][2] = segments[i-1][2]\n",
    "\n",
    "# Zeichnen\n",
    "for s, e, is_better in segments:\n",
    "    seg = slice(s, e + 1)\n",
    "    color = \"green\" if is_better else \"red\"\n",
    "    plt.fill_between(x_smooth[seg], rp_smooth[seg], avg_smooth[seg],\n",
    "                     alpha=0.4, color=color)\n",
    "    \n",
    "\n",
    "plt.xticks(x, ['Age', 'Health', 'Physical Health Days', 'Smoking Habits', 'BMI', 'Physical Activities', 'Sleep', 'Alcohol Consumption', 'Last Checkup'], rotation=30, ha=\"right\")\n",
    "# plt.ylabel(\"Scaled values (01)\")\n",
    "plt.title(\"You vs. Average\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"x\",alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce2731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AgeCategory',\n",
       " 'GeneralHealth',\n",
       " 'PhysicalHealthDays',\n",
       " 'SmokerStatus',\n",
       " 'ECigaretteUsageBMI',\n",
       " 'PhysicalActivities',\n",
       " 'SleepHours',\n",
       " 'AlcoholDrinkers',\n",
       " 'LastCheckupTime']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (9,) (9,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 46\u001b[0m\n\u001b[1;32m     31\u001b[0m rp_vals \u001b[38;5;241m=\u001b[39m rp_values\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     33\u001b[0m higher_better \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m,   \u001b[38;5;66;03m# AgeCategory: higher = worse\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,    \u001b[38;5;66;03m# GeneralHealth: higher = better\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m   \u001b[38;5;66;03m# LastCheckupTime: higher = better\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     ])  \n\u001b[0;32m---> 46\u001b[0m better_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(higher_better, rp_vals \u001b[38;5;241m>\u001b[39m avg_vals, rp_vals \u001b[38;5;241m<\u001b[39m avg_vals)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Scaling 01\u001b[39;00m\n\u001b[1;32m     49\u001b[0m df_min \u001b[38;5;241m=\u001b[39m df_feat[features]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (9,) (9,) "
     ]
    }
   ],
   "source": [
    "# Features that should be shown in graph\n",
    "features = [\n",
    "    'AgeCategory',\n",
    "    'GeneralHealth',\n",
    "    'PhysicalHealthDays',\n",
    "    'SmokerStatus',\n",
    "    'ECigaretteUsage'\n",
    "    'BMI',\n",
    "    'PhysicalActivities',\n",
    "    'SleepHours',\n",
    "    'AlcoholDrinkers',\n",
    "    'LastCheckupTime'\n",
    "    ]\n",
    "for col, mapping in mappers.items():\n",
    "    df_feat[col] = df_feat[col].map(mapping)\n",
    "    rp_feat[col] = rp_feat[col].map(mapping)\n",
    "\n",
    "# Ensure numeric for continuous vars\n",
    "df_feat[\"SleepHours\"] = df_feat[\"SleepHours\"].astype(float)\n",
    "rp_feat[\"SleepHours\"] = rp_feat[\"SleepHours\"].astype(float)\n",
    "df_feat[\"BMI\"] = df_feat[\"BMI\"].astype(float)\n",
    "rp_feat[\"BMI\"] = rp_feat[\"BMI\"].astype(float)\n",
    "\n",
    "# Mean & person values\n",
    "df_avg = df_feat.mean()\n",
    "rp_values = rp_feat.iloc[0]\n",
    "\n",
    "x = np.arange(len(features))\n",
    "avg_vals = df_avg.values\n",
    "rp_vals = rp_values.values\n",
    "\n",
    "higher_better = np.array([\n",
    "    False,   # AgeCategory: higher = worse\n",
    "    True,    # GeneralHealth: higher = better\n",
    "    False,   # PhysicalHealthDays: higher = worse\n",
    "    False,   # SmokerStatus: higher = better (Never smoked > daily smoking),\n",
    "    False,   # ECigaretteUsage: Same as with smoking\n",
    "    False,   # BMI: higher = worse\n",
    "    True,    # PhysicalActivities: higher = better\n",
    "    True,    # SleepHours: higher = better\n",
    "    False,   # AlcoholDrinkers: higher = better (No > Yes)\n",
    "    True   # LastCheckupTime: higher = better\n",
    "    ])  \n",
    "\n",
    "better_mask = np.where(higher_better, rp_vals > avg_vals, rp_vals < avg_vals)\n",
    "\n",
    "# Scaling 01\n",
    "df_min = df_feat[features].min().values\n",
    "df_max = df_feat[features].max().values\n",
    "\n",
    "avg_scaled = (avg_vals - df_min) / (df_max - df_min)\n",
    "rp_scaled = (rp_vals - df_min) / (df_max - df_min)\n",
    "\n",
    "\n",
    "\n",
    "# Smooth x-axis\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)\n",
    "\n",
    "# Smooth curves\n",
    "spl_you = PchipInterpolator(x, rp_scaled)\n",
    "spl_avg = PchipInterpolator(x, avg_scaled)\n",
    "\n",
    "rp_smooth = spl_you(x_smooth)\n",
    "avg_smooth = spl_avg(x_smooth)\n",
    "\n",
    "# Plot showcase and markings if better/worse\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_smooth, rp_smooth, label=\"Your values\", color=\"#0098df\")\n",
    "plt.plot(x_smooth, avg_smooth, label=\"Average\", color=\"#fb4a4a\")\n",
    "\n",
    "# saubere Segmentgrenzen ohne L칲cke\n",
    "bounds = np.concatenate(([x[0] - 0.5],\n",
    "                (x[:-1] + x[1:]) / 2,\n",
    "                [x[-1] + 0.5]))\n",
    "\n",
    "for i in range(len(features)):\n",
    "    seg = (x_smooth >= bounds[i]) & (x_smooth <= bounds[i+1])\n",
    "    color = \"#0a6917\" if better_mask[i] else \"#fb4a4a\"\n",
    "    plt.fill_between(x_smooth[seg], rp_smooth[seg], avg_smooth[seg],\n",
    "                    alpha=0.5, color=color)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])     \n",
    "plt.xticks(x, ['General Health', 'Age', 'Physical Health Days', \n",
    "            'Last Checkup', 'Physcial Activities', 'Sleep Duration', \n",
    "            'Smoking Habits', 'E-Cigarette Use', 'Alcohol Consumption', \n",
    "            'BMI'], \n",
    "            rotation=30, ha=\"right\")\n",
    "plt.title(\"You vs. Average\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1c679de-d1ce-4a55-970e-eb3033fac957",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 63\u001b[0m\n\u001b[1;32m     31\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mYou are a simple, realistic health advisor, to append an Heart Disease Risk model.\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mYou MUST base all judgments only on the numeric lists and rules below.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124m8) Do NOT use numbers in the response. Do NOT directly talk about scaling or data.\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Send request\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     64\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-5.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}])\n\u001b[1;32m     66\u001b[0m advice_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1194\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m   1195\u001b[0m             {\n\u001b[1;32m   1196\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1197\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1198\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1199\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1201\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1202\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1203\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1204\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1205\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1206\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1208\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1209\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1210\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m   1211\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1212\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_key,\n\u001b[1;32m   1213\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_cache_retention\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_cache_retention,\n\u001b[1;32m   1214\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m   1215\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1216\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafety_identifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: safety_identifier,\n\u001b[1;32m   1217\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1218\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1219\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1220\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1221\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1222\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1223\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1224\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1225\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1226\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1227\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1228\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1229\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: verbosity,\n\u001b[1;32m   1230\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[1;32m   1231\u001b[0m             },\n\u001b[1;32m   1232\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[1;32m   1233\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[1;32m   1234\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[1;32m   1235\u001b[0m         ),\n\u001b[1;32m   1236\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1237\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1238\u001b[0m         ),\n\u001b[1;32m   1239\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1240\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1241\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m   1242\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1046\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': \"You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: For security reasons, we cannot provide the private API key we initially used in this code cell.\n",
    "# In order for the code to run, input a new API key/ run streamlit\n",
    "#*************************************\n",
    "\n",
    "# Language Model advice web - Help fixing your bad values\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "# Information to forward to GPT for understanding prediction, feature averages and person values \n",
    "risk_status = \"High risk\" if random_person_pred == 1 else \"Low risk\"\n",
    "person_scaled_list = rp_scaled.tolist()\n",
    "average_scaled_list = avg_scaled.tolist()\n",
    "feature_list = features\n",
    "better_list = higher_better.tolist()\n",
    "\n",
    "# Text to explain number higher better logic for each specific column\n",
    "direction_text = \"\"\"\n",
    "GeneralHealth: higher = better\n",
    "AgeCategory: higher = worse\n",
    "PhysicalHealthDays: higher = worse\n",
    "LastCheckupTime: higher = better\n",
    "PhysicalActivities: higher = better\n",
    "SleepHours: higher = better\n",
    "SmokerStatus: higher = worse\n",
    "ECigaretteUsage: higher = worse\n",
    "AlcoholDrinkers: higher = worse\n",
    "BMI: higher = worse\n",
    "\"\"\"\n",
    "\n",
    "# Promt to forward to GPT\n",
    "prompt = f\"\"\"\n",
    "You are a simple, realistic health advisor, to append an Heart Disease Risk model.\n",
    "You MUST base all judgments only on the numeric lists and rules below.\n",
    "Do not use stereotypes or general knowledge beyond these values.\n",
    "\n",
    "Model prediction: {risk_status}\n",
    "\n",
    "Features in this order:\n",
    "{feature_list}\n",
    "Person's scaled values (same order as features):\n",
    "{person_scaled_list}\n",
    "Average scaled values (same order as features):\n",
    "{average_scaled_list}\n",
    "\n",
    "How to interpret higher values (each feature):\n",
    "{direction_text}\n",
    "\n",
    "TASK: Compare the person's medical values for assessings heart disease risk against the average values and give clear, medical advice for improvement.\n",
    "The response should be:\n",
    "\n",
    "1) Adressed to the person the values are of\n",
    "2) about 4-6 Sentences in english - structure them well dont make them too long (if needed exceed 4-6 setnences by spliting a long one in 2)\n",
    "3) If risk is low start with good things, if high start with bad - keep in mind the higher - lower logic \n",
    "4) If a value is at the best level after the low/high logic dont suggest improvenements but tips to keep this as a strength\n",
    "5) If there are no clearly good areas, do not invent any. It is fine to say if most areas need attention. \n",
    "6) Give clear, practical lifestyle suggestions where meaningful - for example, (not necessarly use this) try quitting app, help groups, \n",
    "   set limits, exercise with friends, dry janurary etc., and concrete suggestions how to do so\n",
    "7) Keep the tone realistic and neutral, not overly optimistic.\n",
    "8) Do NOT use numbers in the response. Do NOT directly talk about scaling or data.\n",
    "\"\"\"\n",
    "\n",
    "# Send request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "advice_text = response.choices[0].message.content\n",
    "\n",
    "# Output\n",
    "symbol = \"游릭\" if risk_status == \"Low risk\" else \"救뎊"\n",
    "print(f\"Heart Disease Model: {risk_status} {symbol}\")\n",
    "print()\n",
    "print(advice_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced25f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
